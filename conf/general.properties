dependencies.externalclasspath='/data/DEVP_DE/share/lib/ebip_dp__lib-commons_1.1.0.jar;/data/DEVP_DE/share/lib/ebip_dp__lib-commons_1.1.0.jar;/data/DEVP_DE/share/lib/ebip_dp__srv-schemareg_1.0.0.jar;/data/SYS/share/lib/spark-avro_2.11-4.0.0.jar;/data/SYS/share/lib/kafka_2.11-2.0.0.3.1.0.0-78.jar;/data/SYS/share/lib/kafka-clients-2.0.0.3.1.0.0-78.jar; /usr/hdp/current/spark2-client/jars/datanucleus-rdbms-3.2.9.jar;/usr/hdp/current/spark2-client/jars/datanucleus-core-3.2.10.jar;/usr/hdp/current/spark2-client/jars/datanucleus-api-jdo-3.2.6.jar;'
dependencies.driverclasspath='/data/SYS/share/lib/avro-1.8.1.jar;'

spark.master=yarn
spark.deploy.mode=cluster

#
# Kerberos properties
#
kerberos.enabled=TRUE
kerberos.principal=E032_S_DP-DE-E-DP@EMEA.CORPDS.NET  
kerberos.keytab=/etc/security/keytabs/e032_s_dp-de-e-dp.keytab
#
# Synthetic key client configuration
#
rest.protocol=http
rest.host=depuasdhb220.epu.corpintra.net
rest.port=12002
#
# Kafka properties
#
bootstrap.servers=depubidcp232.epu.corpintra.net:9092
security.protocol=SASL_SSL
compression.type=snappy
auto.offset.reset=latest
group.id=ogg-datagen

key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.ByteArrayDeserializer

#Client Properties file
kafka.client.properties.file=/data/SYS/share/conf/KIP/client.properties
#
# Schemaregistry Webservice properties
#
schemaregistry.protocol=http
schemaregistry.host=depuasdhb220.epu.corpintra.net
schemaregistry.port=12001

# Oracle connection details - common for all sources
sqoop.oracle.jceks=jceks://hdfs/user/e032_s_dp-de-e-dp/oracle.password.jceks

#sqoop.oracle.env=/data/DEVP_DE/ebip/dp/share/bin/Oracle/env.sh

# Hive JDBC URL
hive.jdbc.url='jdbc:hive2://depuasdhb201.epu.corpintra.net:2181,depuasdhb202.epu.corpintra.net:2181,depubsdhb201.epu.corpintra.net:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2;principal=E032_S_D-HIVE/_HOST@EMEA.CORPDS.NET'
# HDFS
hdfs.core.site.file=/usr/hdp/current/hadoop-client/conf/core-site.xml

#Choose between "etl", "recovery" and "standard".
usage_type=standard
#Choose between "dev", "dev_kerberos" and "dfs".
env=mbb
jar.filepath=ebip_dp__inf-oracle2kafka_1.1.1.jar
class=com.daimler.mbb.ebip.dp.metadata.Main
applicationspecific.log4j=conf/log4j.properties
generalproppath=conf/general.properties

#
#security settings
#
keytab.jaas.file=/data/DEVP_DE/ebip/dp/share/conf/kafka_client_jaas.conf
local.jaas.file=/usr/hdp/current/kafka-broker/config/kafka_client_jaas.conf

distributed.files=/etc/security/keytabs/spnego.service.ebip_dp.keytab,/etc/security/keytabs/e032_s_dp-de-e-dp.keytab,/data/DEVP_DE/ebip/dp/share/conf/kafka_client_jaas.conf,/usr/hdp/current/spark2-client/conf/hive-site.xml,/usr/hdp/current/hadoop-client/conf/core-site.xml


# Oozie related options
oozie.hive.site.file=/etc/hive/conf/hive-site.xml
# This is used to override fs.defaultFS option in core-site.xml file. Without that host in original value cannot be resolved
# Delete or leave blank to turn off override
oozie.hdfs.default.fs='hdfs://depuasdhb201.epu.corpintra.net hdfs://depuasdhb202.epu.corpintra.net'
oozie.job.tracker.address=depuasdhb202:8050
oozie.name.node=hdfs://ebiphdpdeva
oozie.hadoop.user=e032_s_dp-de-e-dp
oozie.address=https://depuasdhb201.epu.corpintra.net:11443/oozie
oozie.kinit.hcat.metastore.uri=thrift://depuasdhb202.epu.corpintra.net:9083
oozie.kinit.hive2.server.principal=E032_S_D-HIVE/_HOST@EMEA.CORPDS.NET
oozie.hive2.jdbc.url='jdbc:hive2://depuasdhb201.epu.corpintra.net:2181,depuasdhb202.epu.corpintra.net:2181,depubsdhb201.epu.corpintra.net:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2'
