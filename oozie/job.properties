# Oozie Job properties file for Module: ICE
# Environment variables, jobTracker stands for YARN, nameNode stand for HDFS client address
job_tracker=depuasdhb202:8050
name_node=hdfs://ebiphdpdeva
hive2_server_principal=E032_S_D-HIVE/_HOST@EMEA.CORPDS.NET
hive2_jdbc_url=jdbc:hive2://depuasdhb201.epu.corpintra.net:2181,depuasdhb202.epu.corpintra.net:2181,depubsdhb201.epu.corpintra.net:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2
# Oozie will use its own libraries -> share library located at oozie home dir on HDFS
oozie.use.system.libpath=true
# Switch off validation of workflow - since it has bug on HDP2.6.1, that causing validation failure.
# TODO: Check if this parameters are required in HDP3.1
oozie.validate.ForkJoin=false
oozie.wf.validate.ForkJoin=false
### ATTENTION! Everything that located below is Auto Generated!
### Project specific variables, generated from /data/{MBBHDP_TENANT}/ebip/db/initialload-oracle-pipeline/current/conf/initialload-oracle-pipeline_ICE.properties
### TODO: It is advised to at least check this section!
module_name=ICE
service_user=e032_s_dp-de-e-dp
oozie_home_path=${name_node}/user/${service_user}/oozie-initial-load-${module_name}
## Oozie PATH configuration
oozie_lib_path=${oozie_home_path}/lib
oozie_wf_path=${oozie_home_path}/workflow
oozie.wf.application.path=${oozie_wf_path}/workflow.xml
# Schema to Read from Oracle
sqoop_schema=WKFLO5_SCHEMA_25
# Meta data database and table in Hive
hive_database_4_metadata=DEVP_DE_ebip_dp__metadata
hive_table_4_metadata=CALMS_ICE_metadata
hive_table_names=ICEREPORTDOCUMENT,ICEREPORTSLICE
# Data database consist of Prefix and Schema
hive_database_4_data=DEVP_DE_ebip_dp__WKFLO5_SCHEMA_25
hive_tmp_database_4_data=DEVP_DE_ebip_dp__WKFLO5_SCHEMA_25_TMP
database_summary=DEVP_DE_ebip_dp__countsummaries
table_summary=tablecount_ICE
table_summary_tmp=tablecount_ICE_tmp
# Sqoop connection details
## Sqoop connection credentials
sqoop_connection_jceks_file=jceks://hdfs/user/e032_s_dp-de-e-dp/oracle.password.jceks
sqoop_connection_credentials=-Dhadoop.security.credential.provider.path=${sqoop_connection_jceks_file}
## Sqoop connection string
sqoop_connection_url_host=devp-getonecms-pink.epu.corpintra.net
sqoop_connection_url_port=1521			
sqoop_connection_url_service_name=GETONECMS-E07.DEVP
sqoop_connection_url_global_name=GETONECMS-E07.DEVP
sqoop_connection_url=jdbc:oracle:thin:@(DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = ${sqoop_connection_url_host}) (PORT = ${sqoop_connection_url_port})))(CONNECT_DATA = (SERVICE_NAME = ${sqoop_connection_url_service_name})(GLOBAL_NAME = ${sqoop_connection_url_global_name})))
## Sqoop connection Username
sqoop_connection_username=APP_HDP
sqoop_connection_password=calms.password.alias
# Step Variables
## Meta Data reading
step_1_sqoop_query=SELECT OWNER, TABLE_NAME, COLUMN_NAME, DATA_TYPE, DATA_PRECISION, DATA_SCALE, CAST(CHAR_LENGTH AS VARCHAR2(30)) CHAR_LENGTH, COLUMN_ID FROM DBA_TAB_COLUMNS WHERE \$CONDITIONS AND OWNER IN ('${sqoop_schema}')
## SCN Number reading
step_3_sqoop_query=SELECT TO_CHAR(CURRENT_SCN) FROM v\$database WHERE \$CONDITIONS
step_3_scn_hdfs_dir=${oozie_home_path}/scn
## Sqoop Query location
step_5_sqoop_query_hdfs_prefix=initialload_select_statement_
step_5_sqoop_query_hdfs_dir=${step_5_sqoop_query_hdfs_prefix}${sqoop_schema}.txt
step_5_common_properties_file=initialload-oracle-pipeline.properties
step_5_property_file=initialload-oracle-pipeline_${module_name}.properties
step_5_libs_path=${oozie_lib_path}/initialload
# Spark
step_8_libs_path=${oozie_lib_path}/datagen
step_8_spark_master=yarn
step_8_spark_mode=cluster
step_8_spark_zookeper=oozie-datagen.zookeeper.sasl.client.username
step_8_spark_options=-Dzookeeper.sasl.client.username=${step_7_spark_zookeper} -Djava.security.auth.login.config=kafka_client_jaas.conf -Dgeneral.properties=general.properties -Dinitialload-oracle-pipeline.properties=initialload-oracle-pipeline_ICE.properties -Dogg.tokens.csn=oozie-initial-load-ICE/scn
target_dir_meta=/warehouse/tablespace/managed/hive/devp_de_ebip_dp__metadata.db/ice_metadata
target_dir_data=/warehouse/tablespace/managed/hive/devp_de_ebip_dp__ice_tmp.db
## Provide list of topics seperated by comma(,)
kafka_topic_list=DEVP_DE_ogg_ice_data,DEVP_DE_ogg_ice_schema
kafka_zookeeper=
